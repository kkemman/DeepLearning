{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.8945</td>\n",
       "      <td>0.3145</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>I</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>F</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>I</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.4275</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.1615</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>F</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.3945</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>4147</td>\n",
       "      <td>M</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.6645</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148</td>\n",
       "      <td>M</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.175</td>\n",
       "      <td>2.0505</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>4149</td>\n",
       "      <td>I</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>4150</td>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>4151</td>\n",
       "      <td>I</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>4152</td>\n",
       "      <td>I</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>4153</td>\n",
       "      <td>I</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>4154</td>\n",
       "      <td>I</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>4155</td>\n",
       "      <td>I</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.3805</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>4156</td>\n",
       "      <td>M</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>4157</td>\n",
       "      <td>M</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>4158</td>\n",
       "      <td>I</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>4159</td>\n",
       "      <td>F</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>4160</td>\n",
       "      <td>F</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0530</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>4161</td>\n",
       "      <td>F</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.4255</td>\n",
       "      <td>0.2630</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>4162</td>\n",
       "      <td>M</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>4163</td>\n",
       "      <td>I</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>4164</td>\n",
       "      <td>I</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>4165</td>\n",
       "      <td>I</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>4166</td>\n",
       "      <td>I</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>4167</td>\n",
       "      <td>M</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>4168</td>\n",
       "      <td>F</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>4169</td>\n",
       "      <td>M</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.7910</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>4170</td>\n",
       "      <td>M</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>4171</td>\n",
       "      <td>M</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>4172</td>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>4173</td>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>4174</td>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>4175</td>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>4176</td>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0        0   M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1        1   M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2        2   F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3        3   M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4        4   I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "5        5   I   0.425     0.300   0.095        0.3515          0.1410   \n",
       "6        6   F   0.530     0.415   0.150        0.7775          0.2370   \n",
       "7        7   F   0.545     0.425   0.125        0.7680          0.2940   \n",
       "8        8   M   0.475     0.370   0.125        0.5095          0.2165   \n",
       "9        9   F   0.550     0.440   0.150        0.8945          0.3145   \n",
       "10      10   F   0.525     0.380   0.140        0.6065          0.1940   \n",
       "11      11   M   0.430     0.350   0.110        0.4060          0.1675   \n",
       "12      12   M   0.490     0.380   0.135        0.5415          0.2175   \n",
       "13      13   F   0.535     0.405   0.145        0.6845          0.2725   \n",
       "14      14   F   0.470     0.355   0.100        0.4755          0.1675   \n",
       "15      15   M   0.500     0.400   0.130        0.6645          0.2580   \n",
       "16      16   I   0.355     0.280   0.085        0.2905          0.0950   \n",
       "17      17   F   0.440     0.340   0.100        0.4510          0.1880   \n",
       "18      18   M   0.365     0.295   0.080        0.2555          0.0970   \n",
       "19      19   M   0.450     0.320   0.100        0.3810          0.1705   \n",
       "20      20   M   0.355     0.280   0.095        0.2455          0.0955   \n",
       "21      21   I   0.380     0.275   0.100        0.2255          0.0800   \n",
       "22      22   F   0.565     0.440   0.155        0.9395          0.4275   \n",
       "23      23   F   0.550     0.415   0.135        0.7635          0.3180   \n",
       "24      24   F   0.615     0.480   0.165        1.1615          0.5130   \n",
       "25      25   F   0.560     0.440   0.140        0.9285          0.3825   \n",
       "26      26   F   0.580     0.450   0.185        0.9955          0.3945   \n",
       "27      27   M   0.590     0.445   0.140        0.9310          0.3560   \n",
       "28      28   M   0.605     0.475   0.180        0.9365          0.3940   \n",
       "29      29   M   0.575     0.425   0.140        0.8635          0.3930   \n",
       "...    ...  ..     ...       ...     ...           ...             ...   \n",
       "4147  4147   M   0.695     0.550   0.195        1.6645          0.7270   \n",
       "4148  4148   M   0.770     0.605   0.175        2.0505          0.8005   \n",
       "4149  4149   I   0.280     0.215   0.070        0.1240          0.0630   \n",
       "4150  4150   I   0.330     0.230   0.080        0.1400          0.0565   \n",
       "4151  4151   I   0.350     0.250   0.075        0.1695          0.0835   \n",
       "4152  4152   I   0.370     0.280   0.090        0.2180          0.0995   \n",
       "4153  4153   I   0.430     0.315   0.115        0.3840          0.1885   \n",
       "4154  4154   I   0.435     0.330   0.095        0.3930          0.2190   \n",
       "4155  4155   I   0.440     0.350   0.110        0.3805          0.1575   \n",
       "4156  4156   M   0.475     0.370   0.110        0.4895          0.2185   \n",
       "4157  4157   M   0.475     0.360   0.140        0.5135          0.2410   \n",
       "4158  4158   I   0.480     0.355   0.110        0.4495          0.2010   \n",
       "4159  4159   F   0.560     0.440   0.135        0.8025          0.3500   \n",
       "4160  4160   F   0.585     0.475   0.165        1.0530          0.4580   \n",
       "4161  4161   F   0.585     0.455   0.170        0.9945          0.4255   \n",
       "4162  4162   M   0.385     0.255   0.100        0.3175          0.1370   \n",
       "4163  4163   I   0.390     0.310   0.085        0.3440          0.1810   \n",
       "4164  4164   I   0.390     0.290   0.100        0.2845          0.1255   \n",
       "4165  4165   I   0.405     0.300   0.085        0.3035          0.1500   \n",
       "4166  4166   I   0.475     0.365   0.115        0.4990          0.2320   \n",
       "4167  4167   M   0.500     0.380   0.125        0.5770          0.2690   \n",
       "4168  4168   F   0.515     0.400   0.125        0.6150          0.2865   \n",
       "4169  4169   M   0.520     0.385   0.165        0.7910          0.3750   \n",
       "4170  4170   M   0.550     0.430   0.130        0.8395          0.3155   \n",
       "4171  4171   M   0.560     0.430   0.155        0.8675          0.4000   \n",
       "4172  4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173  4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174  4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175  4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176  4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "5             0.0775        0.1200      8  \n",
       "6             0.1415        0.3300     20  \n",
       "7             0.1495        0.2600     16  \n",
       "8             0.1125        0.1650      9  \n",
       "9             0.1510        0.3200     19  \n",
       "10            0.1475        0.2100     14  \n",
       "11            0.0810        0.1350     10  \n",
       "12            0.0950        0.1900     11  \n",
       "13            0.1710        0.2050     10  \n",
       "14            0.0805        0.1850     10  \n",
       "15            0.1330        0.2400     12  \n",
       "16            0.0395        0.1150      7  \n",
       "17            0.0870        0.1300     10  \n",
       "18            0.0430        0.1000      7  \n",
       "19            0.0750        0.1150      9  \n",
       "20            0.0620        0.0750     11  \n",
       "21            0.0490        0.0850     10  \n",
       "22            0.2140        0.2700     12  \n",
       "23            0.2100        0.2000      9  \n",
       "24            0.3010        0.3050     10  \n",
       "25            0.1880        0.3000     11  \n",
       "26            0.2720        0.2850     11  \n",
       "27            0.2340        0.2800     12  \n",
       "28            0.2190        0.2950     15  \n",
       "29            0.2270        0.2000     11  \n",
       "...              ...           ...    ...  \n",
       "4147          0.3600        0.4450     11  \n",
       "4148          0.5260        0.3550     11  \n",
       "4149          0.0215        0.0300      6  \n",
       "4150          0.0365        0.0460      7  \n",
       "4151          0.0355        0.0410      6  \n",
       "4152          0.0545        0.0615      7  \n",
       "4153          0.0715        0.1100      8  \n",
       "4154          0.0750        0.0885      6  \n",
       "4155          0.0895        0.1150      6  \n",
       "4156          0.1070        0.1460      8  \n",
       "4157          0.1045        0.1550      8  \n",
       "4158          0.0890        0.1400      8  \n",
       "4159          0.1615        0.2590      9  \n",
       "4160          0.2170        0.3000     11  \n",
       "4161          0.2630        0.2845     11  \n",
       "4162          0.0680        0.0920      8  \n",
       "4163          0.0695        0.0790      7  \n",
       "4164          0.0635        0.0810      7  \n",
       "4165          0.0505        0.0880      7  \n",
       "4166          0.0885        0.1560     10  \n",
       "4167          0.1265        0.1535      9  \n",
       "4168          0.1230        0.1765      8  \n",
       "4169          0.1800        0.1815     10  \n",
       "4170          0.1955        0.2405     10  \n",
       "4171          0.1720        0.2290      8  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/resources/1weeks/abalone.csv\", engine =\"python\")\n",
    "#데이터 확인\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.8945</td>\n",
       "      <td>0.3145</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.4275</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.1615</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.3945</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>4147</td>\n",
       "      <td>2</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.6645</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148</td>\n",
       "      <td>2</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.175</td>\n",
       "      <td>2.0505</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>4149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>4150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>4151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>4153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>4154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>4155</td>\n",
       "      <td>1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.3805</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>4156</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>4157</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>4158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>4159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>4160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.0530</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>4161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.4255</td>\n",
       "      <td>0.2630</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>4162</td>\n",
       "      <td>2</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>4163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>4164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>4165</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>4166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>4167</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>4168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>4169</td>\n",
       "      <td>2</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.7910</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>4170</td>\n",
       "      <td>2</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>4171</td>\n",
       "      <td>2</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>4172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>4173</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>4174</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>4175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>4176</td>\n",
       "      <td>2</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0        0    2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1        1    2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2        2    0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3        3    2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4        4    1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "5        5    1   0.425     0.300   0.095        0.3515          0.1410   \n",
       "6        6    0   0.530     0.415   0.150        0.7775          0.2370   \n",
       "7        7    0   0.545     0.425   0.125        0.7680          0.2940   \n",
       "8        8    2   0.475     0.370   0.125        0.5095          0.2165   \n",
       "9        9    0   0.550     0.440   0.150        0.8945          0.3145   \n",
       "10      10    0   0.525     0.380   0.140        0.6065          0.1940   \n",
       "11      11    2   0.430     0.350   0.110        0.4060          0.1675   \n",
       "12      12    2   0.490     0.380   0.135        0.5415          0.2175   \n",
       "13      13    0   0.535     0.405   0.145        0.6845          0.2725   \n",
       "14      14    0   0.470     0.355   0.100        0.4755          0.1675   \n",
       "15      15    2   0.500     0.400   0.130        0.6645          0.2580   \n",
       "16      16    1   0.355     0.280   0.085        0.2905          0.0950   \n",
       "17      17    0   0.440     0.340   0.100        0.4510          0.1880   \n",
       "18      18    2   0.365     0.295   0.080        0.2555          0.0970   \n",
       "19      19    2   0.450     0.320   0.100        0.3810          0.1705   \n",
       "20      20    2   0.355     0.280   0.095        0.2455          0.0955   \n",
       "21      21    1   0.380     0.275   0.100        0.2255          0.0800   \n",
       "22      22    0   0.565     0.440   0.155        0.9395          0.4275   \n",
       "23      23    0   0.550     0.415   0.135        0.7635          0.3180   \n",
       "24      24    0   0.615     0.480   0.165        1.1615          0.5130   \n",
       "25      25    0   0.560     0.440   0.140        0.9285          0.3825   \n",
       "26      26    0   0.580     0.450   0.185        0.9955          0.3945   \n",
       "27      27    2   0.590     0.445   0.140        0.9310          0.3560   \n",
       "28      28    2   0.605     0.475   0.180        0.9365          0.3940   \n",
       "29      29    2   0.575     0.425   0.140        0.8635          0.3930   \n",
       "...    ...  ...     ...       ...     ...           ...             ...   \n",
       "4147  4147    2   0.695     0.550   0.195        1.6645          0.7270   \n",
       "4148  4148    2   0.770     0.605   0.175        2.0505          0.8005   \n",
       "4149  4149    1   0.280     0.215   0.070        0.1240          0.0630   \n",
       "4150  4150    1   0.330     0.230   0.080        0.1400          0.0565   \n",
       "4151  4151    1   0.350     0.250   0.075        0.1695          0.0835   \n",
       "4152  4152    1   0.370     0.280   0.090        0.2180          0.0995   \n",
       "4153  4153    1   0.430     0.315   0.115        0.3840          0.1885   \n",
       "4154  4154    1   0.435     0.330   0.095        0.3930          0.2190   \n",
       "4155  4155    1   0.440     0.350   0.110        0.3805          0.1575   \n",
       "4156  4156    2   0.475     0.370   0.110        0.4895          0.2185   \n",
       "4157  4157    2   0.475     0.360   0.140        0.5135          0.2410   \n",
       "4158  4158    1   0.480     0.355   0.110        0.4495          0.2010   \n",
       "4159  4159    0   0.560     0.440   0.135        0.8025          0.3500   \n",
       "4160  4160    0   0.585     0.475   0.165        1.0530          0.4580   \n",
       "4161  4161    0   0.585     0.455   0.170        0.9945          0.4255   \n",
       "4162  4162    2   0.385     0.255   0.100        0.3175          0.1370   \n",
       "4163  4163    1   0.390     0.310   0.085        0.3440          0.1810   \n",
       "4164  4164    1   0.390     0.290   0.100        0.2845          0.1255   \n",
       "4165  4165    1   0.405     0.300   0.085        0.3035          0.1500   \n",
       "4166  4166    1   0.475     0.365   0.115        0.4990          0.2320   \n",
       "4167  4167    2   0.500     0.380   0.125        0.5770          0.2690   \n",
       "4168  4168    0   0.515     0.400   0.125        0.6150          0.2865   \n",
       "4169  4169    2   0.520     0.385   0.165        0.7910          0.3750   \n",
       "4170  4170    2   0.550     0.430   0.130        0.8395          0.3155   \n",
       "4171  4171    2   0.560     0.430   0.155        0.8675          0.4000   \n",
       "4172  4172    0   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173  4173    2   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174  4174    2   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175  4175    0   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176  4176    2   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "5             0.0775        0.1200      8  \n",
       "6             0.1415        0.3300     20  \n",
       "7             0.1495        0.2600     16  \n",
       "8             0.1125        0.1650      9  \n",
       "9             0.1510        0.3200     19  \n",
       "10            0.1475        0.2100     14  \n",
       "11            0.0810        0.1350     10  \n",
       "12            0.0950        0.1900     11  \n",
       "13            0.1710        0.2050     10  \n",
       "14            0.0805        0.1850     10  \n",
       "15            0.1330        0.2400     12  \n",
       "16            0.0395        0.1150      7  \n",
       "17            0.0870        0.1300     10  \n",
       "18            0.0430        0.1000      7  \n",
       "19            0.0750        0.1150      9  \n",
       "20            0.0620        0.0750     11  \n",
       "21            0.0490        0.0850     10  \n",
       "22            0.2140        0.2700     12  \n",
       "23            0.2100        0.2000      9  \n",
       "24            0.3010        0.3050     10  \n",
       "25            0.1880        0.3000     11  \n",
       "26            0.2720        0.2850     11  \n",
       "27            0.2340        0.2800     12  \n",
       "28            0.2190        0.2950     15  \n",
       "29            0.2270        0.2000     11  \n",
       "...              ...           ...    ...  \n",
       "4147          0.3600        0.4450     11  \n",
       "4148          0.5260        0.3550     11  \n",
       "4149          0.0215        0.0300      6  \n",
       "4150          0.0365        0.0460      7  \n",
       "4151          0.0355        0.0410      6  \n",
       "4152          0.0545        0.0615      7  \n",
       "4153          0.0715        0.1100      8  \n",
       "4154          0.0750        0.0885      6  \n",
       "4155          0.0895        0.1150      6  \n",
       "4156          0.1070        0.1460      8  \n",
       "4157          0.1045        0.1550      8  \n",
       "4158          0.0890        0.1400      8  \n",
       "4159          0.1615        0.2590      9  \n",
       "4160          0.2170        0.3000     11  \n",
       "4161          0.2630        0.2845     11  \n",
       "4162          0.0680        0.0920      8  \n",
       "4163          0.0695        0.0790      7  \n",
       "4164          0.0635        0.0810      7  \n",
       "4165          0.0505        0.0880      7  \n",
       "4166          0.0885        0.1560     10  \n",
       "4167          0.1265        0.1535      9  \n",
       "4168          0.1230        0.1765      8  \n",
       "4169          0.1800        0.1815     10  \n",
       "4170          0.1955        0.2405     10  \n",
       "4171          0.1720        0.2290      8  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#성별은 문자열로 되어 있으므로 정수형으로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Sex', 'Length', 'Diameter', 'Height', 'Whole_weight',\n",
       "       'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#카테고리 확인\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     689\n",
       "10    634\n",
       "8     568\n",
       "11    487\n",
       "7     391\n",
       "12    267\n",
       "6     259\n",
       "13    203\n",
       "14    126\n",
       "5     115\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "4      57\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "3      15\n",
       "21     14\n",
       "23      9\n",
       "22      6\n",
       "24      2\n",
       "27      2\n",
       "1       1\n",
       "25      1\n",
       "2       1\n",
       "26      1\n",
       "29      1\n",
       "Name: Rings, dtype: int64"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rings의 값별 데이터 갯수 확인\n",
    "df['Rings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ring 값이 28에 가장 가까운 데이터 찾아서 복사후 Ring 값을 28로 변경\n",
    "closest_data = df.iloc[(df['Rings'] - 28).abs().argsort()[:1]]\n",
    "new_data = closest_data.copy()\n",
    "new_data['Rings'] = 28\n",
    "\n",
    "# 원본 데이터에 새로운 데이터 추가\n",
    "df = pd.concat([df, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     689\n",
       "10    634\n",
       "8     568\n",
       "11    487\n",
       "7     391\n",
       "12    267\n",
       "6     259\n",
       "13    203\n",
       "14    126\n",
       "5     115\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "4      57\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "3      15\n",
       "21     14\n",
       "23      9\n",
       "22      6\n",
       "24      2\n",
       "27      2\n",
       "28      1\n",
       "1       1\n",
       "25      1\n",
       "2       1\n",
       "26      1\n",
       "29      1\n",
       "Name: Rings, dtype: int64"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rings에 28 있는지 확인\n",
    "df['Rings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Small     2096\n",
       "Medium    2019\n",
       "Large       62\n",
       "Name: Ring_Group, dtype: int64"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rings를 나눌 구간을 정하고 레이블 정의\n",
    "bins = [0, 10, 20, df['Rings'].max()]\n",
    "labels = ['Small', 'Medium', 'Large']\n",
    "\n",
    "# 새로운 컬럼 'Ring_Group'을 추가해서 구간 나누기\n",
    "df['Ring_Group'] = pd.cut(df['Rings'], bins=bins, labels=labels, right=False)\n",
    "df['Ring_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole_weight      0\n",
       "Shucked_weight    0\n",
       "Viscera_weight    0\n",
       "Shell_weight      0\n",
       "Rings             0\n",
       "Ring_Group        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#겉측지 확인\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole_weight      0\n",
       "Shucked_weight    0\n",
       "Viscera_weight    0\n",
       "Shell_weight      0\n",
       "Rings             0\n",
       "Ring_Group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count')"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 레이블별 갯수 확인\n",
    "label_counts = df['Ring_Group'].value_counts()\n",
    "\n",
    "# 바 그래프 그리기\n",
    "label_counts.plot(kind='bar')\n",
    "\n",
    "# 그래프 제목 및 라벨 설정\n",
    "plt.title('Label Count')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_LE = df.filter(regex='Length') \n",
    "df_HE = df.filter(regex='Height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LE.insert(1, 'Ring_Group', df['Ring_Group'])\n",
    "df_HE.insert(1, 'Ring_Group', df['Ring_Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Ring_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.425</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.530</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.545</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.475</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.550</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.525</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.430</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.490</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.535</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.470</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.500</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.355</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.440</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.365</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.450</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.355</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.380</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.565</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.550</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.615</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.560</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.580</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.590</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.605</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.575</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>0.770</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>0.280</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>0.330</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>0.350</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>0.370</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>0.430</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>0.435</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>0.440</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>0.475</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>0.475</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>0.480</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>0.560</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>0.585</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>0.585</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>0.385</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>0.390</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>0.390</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>0.405</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>0.475</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>0.500</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>0.515</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>0.520</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>0.550</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>0.560</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.565</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.590</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.600</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.625</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.710</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>0.700</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length Ring_Group\n",
       "0      0.455     Medium\n",
       "1      0.350      Small\n",
       "2      0.530      Small\n",
       "3      0.440     Medium\n",
       "4      0.330      Small\n",
       "5      0.425      Small\n",
       "6      0.530      Large\n",
       "7      0.545     Medium\n",
       "8      0.475      Small\n",
       "9      0.550     Medium\n",
       "10     0.525     Medium\n",
       "11     0.430     Medium\n",
       "12     0.490     Medium\n",
       "13     0.535     Medium\n",
       "14     0.470     Medium\n",
       "15     0.500     Medium\n",
       "16     0.355      Small\n",
       "17     0.440     Medium\n",
       "18     0.365      Small\n",
       "19     0.450      Small\n",
       "20     0.355     Medium\n",
       "21     0.380     Medium\n",
       "22     0.565     Medium\n",
       "23     0.550      Small\n",
       "24     0.615     Medium\n",
       "25     0.560     Medium\n",
       "26     0.580     Medium\n",
       "27     0.590     Medium\n",
       "28     0.605     Medium\n",
       "29     0.575     Medium\n",
       "...      ...        ...\n",
       "4148   0.770     Medium\n",
       "4149   0.280      Small\n",
       "4150   0.330      Small\n",
       "4151   0.350      Small\n",
       "4152   0.370      Small\n",
       "4153   0.430      Small\n",
       "4154   0.435      Small\n",
       "4155   0.440      Small\n",
       "4156   0.475      Small\n",
       "4157   0.475      Small\n",
       "4158   0.480      Small\n",
       "4159   0.560      Small\n",
       "4160   0.585     Medium\n",
       "4161   0.585     Medium\n",
       "4162   0.385      Small\n",
       "4163   0.390      Small\n",
       "4164   0.390      Small\n",
       "4165   0.405      Small\n",
       "4166   0.475     Medium\n",
       "4167   0.500      Small\n",
       "4168   0.515      Small\n",
       "4169   0.520     Medium\n",
       "4170   0.550     Medium\n",
       "4171   0.560      Small\n",
       "4172   0.565     Medium\n",
       "4173   0.590     Medium\n",
       "4174   0.600      Small\n",
       "4175   0.625     Medium\n",
       "4176   0.710     Medium\n",
       "4177   0.700      Large\n",
       "\n",
       "[4177 rows x 2 columns]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Ring_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.095</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.125</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.125</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.150</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.140</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.110</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.135</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.145</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.100</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.130</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.085</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.100</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.080</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.100</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.095</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.100</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.155</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.135</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.165</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.140</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.185</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.140</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.180</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.140</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>0.175</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>0.070</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>0.080</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>0.075</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>0.090</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>0.115</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>0.095</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>0.110</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>0.110</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>0.140</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>0.110</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>0.135</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>0.165</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>0.170</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>0.100</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>0.085</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>0.100</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>0.085</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>0.115</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>0.125</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>0.125</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>0.165</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>0.130</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>0.155</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.165</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.135</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.205</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.150</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.195</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>0.185</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Height Ring_Group\n",
       "0      0.095     Medium\n",
       "1      0.090      Small\n",
       "2      0.135      Small\n",
       "3      0.125     Medium\n",
       "4      0.080      Small\n",
       "5      0.095      Small\n",
       "6      0.150      Large\n",
       "7      0.125     Medium\n",
       "8      0.125      Small\n",
       "9      0.150     Medium\n",
       "10     0.140     Medium\n",
       "11     0.110     Medium\n",
       "12     0.135     Medium\n",
       "13     0.145     Medium\n",
       "14     0.100     Medium\n",
       "15     0.130     Medium\n",
       "16     0.085      Small\n",
       "17     0.100     Medium\n",
       "18     0.080      Small\n",
       "19     0.100      Small\n",
       "20     0.095     Medium\n",
       "21     0.100     Medium\n",
       "22     0.155     Medium\n",
       "23     0.135      Small\n",
       "24     0.165     Medium\n",
       "25     0.140     Medium\n",
       "26     0.185     Medium\n",
       "27     0.140     Medium\n",
       "28     0.180     Medium\n",
       "29     0.140     Medium\n",
       "...      ...        ...\n",
       "4148   0.175     Medium\n",
       "4149   0.070      Small\n",
       "4150   0.080      Small\n",
       "4151   0.075      Small\n",
       "4152   0.090      Small\n",
       "4153   0.115      Small\n",
       "4154   0.095      Small\n",
       "4155   0.110      Small\n",
       "4156   0.110      Small\n",
       "4157   0.140      Small\n",
       "4158   0.110      Small\n",
       "4159   0.135      Small\n",
       "4160   0.165     Medium\n",
       "4161   0.170     Medium\n",
       "4162   0.100      Small\n",
       "4163   0.085      Small\n",
       "4164   0.100      Small\n",
       "4165   0.085      Small\n",
       "4166   0.115     Medium\n",
       "4167   0.125      Small\n",
       "4168   0.125      Small\n",
       "4169   0.165     Medium\n",
       "4170   0.130     Medium\n",
       "4171   0.155      Small\n",
       "4172   0.165     Medium\n",
       "4173   0.135     Medium\n",
       "4174   0.205      Small\n",
       "4175   0.150     Medium\n",
       "4176   0.195     Medium\n",
       "4177   0.185      Large\n",
       "\n",
       "[4177 rows x 2 columns]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Small     2096\n",
       "Medium    2019\n",
       "Large       62\n",
       "Name: Ring_Group, dtype: int64"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LE['Ring_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Small     2096\n",
       "Medium    2019\n",
       "Large       62\n",
       "Name: Ring_Group, dtype: int64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HE['Ring_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 'label' 컬럼을 숫자로 변환\n",
    "df_LE['Ring_Group'] = label_encoder.fit_transform(df_LE['Ring_Group'])\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "# 'label' 컬럼을 숫자로 변환\n",
    "df_HE['Ring_Group'] = label_encoder.fit_transform(df_HE['Ring_Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2096\n",
       "1    2019\n",
       "0      62\n",
       "Name: Ring_Group, dtype: int64"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LE['Ring_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2096\n",
       "1    2019\n",
       "0      62\n",
       "Name: Ring_Group, dtype: int64"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HE['Ring_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length\n",
       "0   0.455\n",
       "1   0.350\n",
       "2   0.530\n",
       "3   0.440\n",
       "4   0.330"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LE_Y=df_LE['Ring_Group']\n",
    "df_LE_X=df_LE.drop('Ring_Group',axis=1)\n",
    "df_LE_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 데이터와 테스트 데이터로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_LE, X_test_LE, y_train_LE, y_test_LE = train_test_split(df_LE_X, \n",
    "                                                    df_LE_Y,\n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    1\n",
       "4    2\n",
       "Name: Ring_Group, dtype: int64"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HE_Y = df_HE['Ring_Group']\n",
    "df_HE_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height\n",
       "0   0.095\n",
       "1   0.090\n",
       "2   0.135\n",
       "3   0.125\n",
       "4   0.080"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HE_X=df_HE.drop('Ring_Group',axis=1)\n",
    "df_HE_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_HE, X_test_HE, y_train_HE, y_test_HE = train_test_split(df_HE_X, \n",
    "                                                    df_HE_Y,\n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>높이와 길이를 각각 훈련과 테스트 데이터로 분리</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3132, 1), (1045, 1), (3132,), (1045,))"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_LE.shape, X_test_LE.shape, y_train_LE.shape, y_test_LE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3132, 1), (1045, 1), (3132,), (1045,))"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_HE.shape, X_test_HE.shape, y_train_HE.shape, y_test_HE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()  # 빈 리스트를 생성하여 시퀀스 데이터와 레이블을 담을 공간을 만듦\n",
    "    for i in range(len(sequences)):  # 전체 시퀀스 데이터를 순회\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps  # 현재 인덱스(i)에서 n_steps만큼 떨어진 시퀀스의 끝을 계산\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):  # 시퀀스 끝이 데이터의 범위를 넘어서는지 확인\n",
    "            break  # 범위를 넘으면 루프 종료\n",
    "        # gather input (X) and output parts (y)\n",
    "        seq_x = sequences[i:end_ix, :-1]  # 입력 데이터 (특징 데이터)\n",
    "        seq_y_values = sequences[i:end_ix, -1]  # 시퀀스 동안의 출력 데이터 (레이블들)\n",
    "        \n",
    "        # 가장 빈번하게 나온 레이블 찾기\n",
    "        most_common_label = Counter(seq_y_values).most_common(1)[0][0]\n",
    "        \n",
    "        X.append(seq_x)  # 입력 데이터 추가\n",
    "        y.append(most_common_label)  # 가장 많이 나온 레이블 추가\n",
    "    \n",
    "    return np.array(X), np.array(y)  # 리스트를 numpy 배열로 변환하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 출력을 하나의 배열로 결합\n",
    "y_train_array_LE = np.array(y_train_LE)\n",
    "train_set_LE = np.c_[X_train_LE, y_train_array_LE]\n",
    "\n",
    "y_test_array_LE = np.array(y_test_LE)\n",
    "test_set_LE = np.c_[X_test_LE, y_test_array_LE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3130, 3, 1) (3130,)\n",
      "(1043, 3, 1) (1043,)\n"
     ]
    }
   ],
   "source": [
    "#3개의 데이터를 포함하도록 시퀀스 데이터를 생성\n",
    "n_step = 3 \n",
    "\n",
    "X_train_seq_LE, y_train_seq_LE = split_sequences(train_set_LE, n_step)\n",
    "print(X_train_seq_LE.shape, y_train_seq_LE.shape)\n",
    "\n",
    "X_test_seq_LE, y_test_seq_LE = split_sequences(test_set_LE, n_step)\n",
    "print(X_test_seq_LE.shape, y_test_seq_LE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_array_HE = np.array(y_train_HE)\n",
    "train_set_HE = np.c_[X_train_HE, y_train_array_HE]\n",
    "\n",
    "y_test_array_HE = np.array(y_test_HE)\n",
    "test_set_HE = np.c_[X_test_HE, y_test_array_HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3130, 3, 1) (3130,)\n",
      "(1043, 3, 1) (1043,)\n"
     ]
    }
   ],
   "source": [
    "X_train_seq_HE, y_train_seq_HE = split_sequences(train_set_HE, n_step)\n",
    "print(X_train_seq_HE.shape, y_train_seq_HE.shape)\n",
    "\n",
    "X_test_seq_HE, y_test_seq_HE = split_sequences(test_set_HE, n_step)\n",
    "print(X_test_seq_HE.shape, y_test_seq_HE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3130, 3)\n",
      "(1043, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert output variables to categorical for CNN\n",
    "y_train_seq_LE = to_categorical(y_train_seq_LE)\n",
    "print(y_train_seq_LE.shape)\n",
    "\n",
    "y_test_seq_LE = to_categorical(y_test_seq_LE)\n",
    "print(y_test_seq_LE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3130, 3)\n",
      "(1043, 3)\n"
     ]
    }
   ],
   "source": [
    "y_train_seq_HE = to_categorical(y_train_seq_HE)\n",
    "print(y_train_seq_HE.shape)\n",
    "\n",
    "y_test_seq_HE = to_categorical(y_test_seq_HE)\n",
    "print(y_test_seq_HE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 3\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train_seq_LE.shape[1], X_train_seq_LE.shape[2], y_train_seq_LE.shape[1]\n",
    "print(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# cnn model vary kernel size\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LSTM과 CNN을 혼합한 모델 생성</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train_seq_HE.shape[1], X_train_seq_HE.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(y_train_seq_HE.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 1, 50)             16600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 19,399\n",
      "Trainable params: 19,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 0.8753 - accuracy: 0.5062 - val_loss: 0.7669 - val_accuracy: 0.5399\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.5151 - val_loss: 0.7699 - val_accuracy: 0.4920\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.5048 - val_loss: 0.7648 - val_accuracy: 0.5399\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.5343 - val_loss: 0.7603 - val_accuracy: 0.5431\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.5424 - val_loss: 0.7642 - val_accuracy: 0.5974\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.5680 - val_loss: 0.7460 - val_accuracy: 0.5591\n",
      "Epoch 7/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.5758 - val_loss: 0.7330 - val_accuracy: 0.6613\n",
      "Epoch 8/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.6042 - val_loss: 0.7241 - val_accuracy: 0.6645\n",
      "Epoch 9/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.6163 - val_loss: 0.7214 - val_accuracy: 0.6198\n",
      "Epoch 10/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.6166 - val_loss: 0.7064 - val_accuracy: 0.6454\n",
      "Epoch 11/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.6297 - val_loss: 0.6986 - val_accuracy: 0.6486\n",
      "Epoch 12/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.6454 - val_loss: 0.6959 - val_accuracy: 0.6645\n",
      "Epoch 13/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.6422 - val_loss: 0.7397 - val_accuracy: 0.6070\n",
      "Epoch 14/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.6397 - val_loss: 0.7032 - val_accuracy: 0.6454\n",
      "Epoch 15/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.6429 - val_loss: 0.7497 - val_accuracy: 0.6006\n",
      "Epoch 16/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6471 - val_loss: 0.7179 - val_accuracy: 0.6326\n",
      "Epoch 17/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6528 - val_loss: 0.6996 - val_accuracy: 0.6518\n",
      "Epoch 18/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.6532 - val_loss: 0.6906 - val_accuracy: 0.6550\n",
      "Epoch 19/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6589 - val_loss: 0.6909 - val_accuracy: 0.6645\n",
      "Epoch 20/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6542 - val_loss: 0.6930 - val_accuracy: 0.6677\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_seq_LE, y_train_seq_LE, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23673942828>"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label = \"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 474us/step - loss: 0.6487 - accuracy: 0.6626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6486566066741943, 0.6626198291778564]"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련 데이터로 성능평가 실시\n",
    "model.evaluate(X_train_seq_LE, y_train_seq_LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 469us/step - loss: 0.6465 - accuracy: 0.6826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6465001106262207, 0.6826462149620056]"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#테스트 데이터로 성능평가 실시\n",
    "model.evaluate(X_test_seq_LE, y_test_seq_LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "y_test_arg=np.argmax(y_test_seq_LE, axis=1)\n",
    "Y_pred = np.argmax(model.predict(X_test_seq_LE),axis=1)\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test_arg, Y_pred)\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))  # 그래프 크기 조절 (너비 8, 높이 6)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 406us/step - loss: 0.6465 - accuracy: 0.6826\n",
      "model saved at  C:/resources/2weeks/LE_Model.h5\n",
      "Accuracy >68.264621\n",
      "Base Loss >0.65\n"
     ]
    }
   ],
   "source": [
    "base_loss,base_accuracy=model.evaluate(X_test_seq_LE, y_test_seq_LE)\n",
    "\n",
    "model_file='C:/resources/2weeks/LE_Model.h5'\n",
    "  \n",
    "tf.keras.models.save_model(model, model_file, include_optimizer=False)\n",
    "print('model saved at ', model_file)\n",
    "#score,keras_file=evaluate_model(trainX,trainy,testX,testy)\n",
    "score=base_accuracy*100\n",
    "print('Accuracy >{:f}'.format(score))\n",
    "print('Base Loss >{:.2f}'.format(base_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train_seq_HE.shape[1], X_train_seq_HE.shape[2])))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(LSTM(50, return_sequences=True))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dense(y_train_seq_HE.shape[1], activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 2, 32)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 1, 50)             16600     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 19,399\n",
      "Trainable params: 19,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "89/89 [==============================] - 1s 4ms/step - loss: 0.8867 - accuracy: 0.4952 - val_loss: 0.7847 - val_accuracy: 0.4441\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.5105 - val_loss: 0.7706 - val_accuracy: 0.6102\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.4909 - val_loss: 0.7770 - val_accuracy: 0.4441\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.5353 - val_loss: 0.7661 - val_accuracy: 0.5399\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.5186 - val_loss: 0.7743 - val_accuracy: 0.4441\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.5211 - val_loss: 0.7700 - val_accuracy: 0.4441\n",
      "Epoch 7/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.5289 - val_loss: 0.7721 - val_accuracy: 0.4441\n",
      "Epoch 8/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.5371 - val_loss: 0.7698 - val_accuracy: 0.4569\n",
      "Epoch 9/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.5431 - val_loss: 0.7682 - val_accuracy: 0.4728\n",
      "Epoch 10/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.5644 - val_loss: 0.7605 - val_accuracy: 0.5847\n",
      "Epoch 11/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.5588 - val_loss: 0.7564 - val_accuracy: 0.5783\n",
      "Epoch 12/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.5790 - val_loss: 0.7547 - val_accuracy: 0.5367\n",
      "Epoch 13/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6035 - val_loss: 0.7496 - val_accuracy: 0.5399\n",
      "Epoch 14/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.6266 - val_loss: 0.7330 - val_accuracy: 0.5815\n",
      "Epoch 15/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.6486 - val_loss: 0.7122 - val_accuracy: 0.6070\n",
      "Epoch 16/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6525 - val_loss: 0.6824 - val_accuracy: 0.6901\n",
      "Epoch 17/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6535 - val_loss: 0.6893 - val_accuracy: 0.6518\n",
      "Epoch 18/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6592 - val_loss: 0.6874 - val_accuracy: 0.6581\n",
      "Epoch 19/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6624 - val_loss: 0.6824 - val_accuracy: 0.6741\n",
      "Epoch 20/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6628 - val_loss: 0.7138 - val_accuracy: 0.6070\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train_seq_HE, y_train_seq_HE, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x236a79b27f0>"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history[\"loss\"], label = \"train\")\n",
    "plt.plot(history2.history[\"val_loss\"], label = \"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 515us/step - loss: 0.6502 - accuracy: 0.6610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6501606702804565, 0.6610223650932312]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_train_seq_HE, y_train_seq_HE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 688us/step - loss: 0.6586 - accuracy: 0.6453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6586031913757324, 0.6452540755271912]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_seq_HE, y_test_seq_HE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAFpCAYAAADtHzMRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHPxJREFUeJzt3XmcX3V97/HXZyYL2SABMhPIBMIqArJYVlEhgBLANsHaW5GitUAqrhRrKdBebS+yWIWWikgquF0KUqDitSxFQ9hXIUAgEKNsE0wiSyAxCUlmvveP+SZ3bkwyk8x3cvidvJ4+fg/nd875/c7n9xhm3vP5fr/nJFJKSJIkaKq6AEmS3i4MRUmSMkNRkqTMUJQkKTMUJUnKDEVJkjJDUZKkzFCUJCkzFCVJygxFSZKyAf19gmUdS7yPXE11ps6qS1A/iYiqS1A/GdI8rN++ufGBtj79vk+3t1f+H16/h6IkaTNRgz+mHD6VJCmzU5QklVGDNstQlCSVUYPhU0NRklRG42diHZpdSZLKsFOUJJXh8KkkSVkNxh4NRUlSGXaKkiRljZ+JdWh2JUkqw05RklRGU+O3ioaiJKmMxs9EQ1GSVIgLbSRJyho/E11oI0nSKnaKkqQyXGgjSVLW+JloKEqSCqnBQhvnFCVJyuwUJUllOKcoSVLW+JloKEqSCqnBnKKhKEkqo/Ez0YU2kiStYqcoSSrDhTaSJGWNn4mGoiSpEBfaSJKU1WCVSg0+giRJZdgpSpLKcPhUkqSs8TPRUJQkFVKDTtE5RUmSMjtFSVIZNWizDEVJUhk1GD41FCVJZTR+JhqKkqRCanDv0xqMAEuSVIadoiSpDOcUJUnKGj8TDUVJUhlhpyhJUpc6hKILbSRJygxFSVIREX179O4c0RwRj0XET/PznSLiwYj4ZUT8KCIG5e2D8/M5ef/43ry/oShJKqIpok+PXvoCMKvb84uAS1JKuwGvA6fk7acAr6eUdgUuycf1/Bl6W4UkSesTEX169OL924Djge/k5wEcCVyfD/k+MDl/PSk/J+8/KnpxEkNRktQo/hn4G6AzP98GWJhSWpmftwNj89djgZcA8v438vHr5erTQu69+14uuuCf6Ozo5ISPTOaU0/6i6pJUwPPPPc9ZXzx79fO57XM5/bOf4qSPf6zCqlTKsUcfz7Bhw2hqamLAgGb+/T+urrqkhtbX1acRMQWY0m3T1JTS1LzvQ8CClNIvIuKIVS9Zy9ukXuxbJ0OxgI6ODs4/70Ku+M7ltLa28rE/PYkjJhzOLrvuUnVp6qPxO43nRzdeA3R9n4+ZcCwTjp5QbVEq6t++dwWjRo2quoxa6Gso5gCcuo7dhwF/FBHHAVsAW9LVOY6MiAG5G2wDXs7HtwPjgPaIGABsBbzWUw09Dp9GxB4RcVZEXBoR/5K/fmdPr9uczHxyJuN2GEfbuDYGDhrIxGOPYfq06VWXpcIeeuAh2sa1sf3221VdivS21J+rT1NKZ6eU2lJK44GPAtNSSicBdwAfyYd9Argpf/2T/Jy8f1pKqcdOcb2hGBFnAdfS1YY+BDycv74mIv62pzffXCyYv4AxY1pXP28Z08r8Bb+tsCL1h9tu+W8mHndM1WWooIjg9FM/w4kf+RjXX3dD1eU0vP5eaLMOZwFnRsQcuuYMr8zbrwS2ydvPBHqVWT0Nn54C7JVSWtF9Y0RcDDwFXLgBhdfW2v72aPz7Oqi7FctXcOcdd/K5Mz5bdSkq6HtXf5eWltG89uprfOrU09lp5/H8wQF/UHVZ6kFKaTowPX/9a+CgtRyzDPiTDX3vnoZPO4Ht17J9O/7f6p/fExFTIuKRiHjkyn+7akNrajitY1qYN2/+6ucL5s2npWV0hRWptHvuuZc99tyDbbbtcfGaGsiqn9Ott9maCUdNYOYTT1VcUWOrqFMsqqdO8Qzg5xHxS/LSVmAHYFdgnX8yd58sXdaxpMcx3Ea319578eILL9LePpfWlhZuveU2LvjaBVWXpYJuvfk2Jh43seoyVNDSJUvpTJ0MGzaMpUuWcv99D/CXp59WdVkNLWowRrbeUEwp3RoRu9PVmo6la1SwHXg4pdSxCeprCAMGDODsc8/i9NM+TWdnJ5NPmMSuu7nytC6WLl3Kg/c9yN99+ZyqS1FBr776Kmd+/osArFzZwbHHT+Sw9x1WcVWN7e3S7fVF9GIxTp9sDp3i5qozrXMEXQ2uDr/ctHZDmof12zd3q3MO7tPv+zfOf7Dy//C8o40kSZkX70uSitiAm3q/bRmKkqQi6jDsbihKkoqoQyg6pyhJUmanKEkqogaNoqEoSSqjDsOnhqIkqQhDUZKkrA6h6EIbSZIyO0VJUhF16BQNRUlSETXIRENRklSGnaIkSVkdQtGFNpIkZXaKkqQi/FcyJEnKapCJhqIkqQznFCVJqhE7RUlSEUHjd4qGoiSpiDoMnxqKkqQiDEVJkrIaZKILbSRJWsVOUZJUhMOnkiRlhqIkSVkdQtE5RUmSMjtFSVIRNWgUDUVJUhl1GD41FCVJRRiKkiRldQhFF9pIkpTZKUqSiqhBo2goSpLKqMPwqaEoSSrCUJQkKatDKLrQRpKkzE5RklREDRpFQ1GSVEYdhk8NRUlSGTUIRecUJUnKDEVJUhER0adHL95/i4h4KCIej4inIuIf8varI+LZiJgZEVdFxMC8PSLi0oiYExFPRMS7ezqHoShJKiKib49eeAs4MqW0L7AfMDEiDgGuBvYA3gUMAU7Nxx8L7JYfU4DLezqBc4qSpCL6e6FNSikBi/PTgfmRUko3d6vhIaAtP50E/CC/7oGIGBkR26WUfrOuc9gpSpKK6O/h03yO5oiYASwAbk8pPdht30DgZODWvGks8FK3l7fnbetkKEqS3hYiYkpEPNLtMWXNY1JKHSml/ejqBg+KiL277f4WcFdK6e5Vb7mW06T11eDwqSSpiL4On6aUpgJTe3nswoiYDkwEZkbEl4HRwF92O6wdGNfteRvw8vre105RklREfy+0iYjRETEyfz0EOBp4JiJOBY4BTkwpdXZ7yU+Aj+dVqIcAb6xvPhHsFCVJhWyCO9psB3w/IprpauquSyn9NCJWAi8A9+cabkwp/SNwM3AcMAdYAnyypxMYitpoVzz17apLUD95YO6cqktQP/nRcf33c7sJVp8+Aey/lu1rzbK86vQzG3IOh08lScrsFCVJRXhDcEmSMkNRkqSsBpnonKIkSavYKUqSinD4VJKkzFCUJCkzFCVJymqQiS60kSRpFTtFSVIRDp9KkrSKoShJUhc7RUmSsqbGz0QX2kiStIqdoiSpCIdPJUnKmgxFSZK61KFTdE5RkqTMTlGSVEQduixDUZJUhHOKkiRldZhTNBQlSUXUoVOswxCwJElF2ClKkopw+FSSpKwOQ4+GoiSpiDrMKRqKkqQi6jB8WoduV5KkIuwUJUlFOHwqSVLW+JFoKEqSCqlDp+icoiRJmZ2iJKmIOnSKhqIkqYg6XJJhKEqSirBTlCQpa/xIdKGNJEmr2SlKkopw+FSSpMxQlCQpc/WpJElZHTpFF9pIkpTZKUqSimj8PtFQlCQVUofhU0NRklREHULROUVJkjJDUZJURET06dGL9x8XEXdExKyIeCoivrDG/r+OiBQR2+bnERGXRsSciHgiIt7d0zkcPpUkFbEJuqyVwBdTSo9GxAjgFxFxe0rp6YgYB3wAeLHb8ccCu+XHwcDl+f/XyVAs5N677+WiC/6Jzo5OTvjIZE457S+qLkkbYPEri5l22XSWLFxKBLzz6Heyz3F7s2zxMm6/ZBqLfruIEaNH8MG/OorBwwcz++45zLjpcQAGbjGA9536XrYdv03Fn0Jrs80Wo/jMvn/OyMFb0pkSP3/pHm55fhoAE3c8gmN2PIKO1MljC2Zy9bM30hzNTHnXSey81Y6klPje09fx9GuzK/4UjaG/L95PKf0G+E3+elFEzALGAk8DlwB/A9zU7SWTgB+klBLwQESMjIjt8vuslaFYQEdHB+efdyFXfOdyWltb+difnsQREw5nl113qbo09VI0N3HoyYcweudtWb50OTf87X/Sts9Ynp0+m7Z3bc/+k/fjsR/P4LEfz+CQPzuYLVtGMOkrH2Lw8MG8+NhL3DX1bj58/uSqP4bWoiN18MNZ1/Pcmy+xRfNgLnjvOTzxyixGDhrBAa378qV7zmNl50q2HDQCgKN2eC8AX7r7f7HloBGcfeBnOefeC0mkKj9GQ9iUC20iYjywP/BgRPwRMDel9PgawTwWeKnb8/a8bZ2h6JxiATOfnMm4HcbRNq6NgYMGMvHYY5g+bXrVZWkDDBs1lNE7bwvAoCGDGDV2FL977Xc8//AL7H747gDsfvjuPPfwCwCMeUcrg4cPBqB1txYWv/q7agpXjxa+9SbPvdn1e3FZx1vMXTyPrbcYyQd2PJybfnUbKztXAvDm8kUAtA3fjidfeWb1tt+tWMrOW+1YTfGbmYiYEhGPdHtMWcdxw4EbgDPoGlI9F/ifazt0LdvW+9fNRodiRHxyY19bNwvmL2DMmNbVz1vGtDJ/wW8rrEh98eaCRbzy3Cu07trC0jeWMmzUUKArOJe+ufT3jp817Vl22H/cpi5TG2H0kG3YactxzFn4HNsNa2GPrXflvPecxZcPPpNdcvC98GY7B7buS1M0MXrINuy81Q5sM2RUxZU3hqaIPj1SSlNTSgd0e0xd8xwRMZCuQLw6pXQjsAuwE/B4RDwPtAGPRsQYujrD7j+cbcDL6/0Mffj8/9CH19ZKWsvfHY1/tc7macWyFfz3N37Ge/78UAYNHdTj8XNnvswzdzzLIScdtAmqU18Mbh7Mme+ewvefvo6lK5fRHE0MGziUv7vvIv73Mzdyxv6nAXBH+328umwhFxx2Np/Y838w+/Vf09nZWXH1jWETrD4N4EpgVkrpYoCU0pMppZaU0viU0ni6gvDdKaV5wE+Aj+dVqIcAb6xvPhF6mFOMiCfWtQtoXcc+css7BeCbl/9r7RedtI5pYd68+aufL5g3n5aW0RVWpI3RsbKT275xO7u9bxd2PngnAIZsNYTfvb6EYaOG8rvXlzBkyyGrj3/1hVe584q7OO7siWwxYouqylYvNEcTX3z3FO55+SEemj8DgFeXLeSheV1f/+qN5+lMiRGDhrNo+WJ+MOs/Vr/2Hw/9Er9ZsqCSuhtNU/+3A4cBJwNPRsSMvO2clNLN6zj+ZuA4YA6wBOhxhLOnhTatwDHA62tsD+C+db0ot7xTAZZ1LKn97PRee+/Fiy+8SHv7XFpbWrj1ltu44GsXVF2WNkBKiTu/fSejxo5i3w/ts3r7+AN2ZPads9l/8n7MvnM24w/sGmJb9Mpibvv6zzjysxMYuf3IqspWL33qXR9n7uJ5/NdzP1+97eH5M9hrm3fw9Guz2W5YCwOamlm0fDGDmgYSEbzVsZx3bftOOlMncxevt7lQtglWn95DDwNxuVtc9XUCPrMh5+gpFH8KDE8pzVhzR0RM35AT1dmAAQM4+9yzOP20T9PZ2cnkEyax626uPG0k856dz+y75rD1DlvzH1+6AYCDTjyQ/Sfvy+2X/JxZ055lxLbD+cCZRwHwi+sfZdniZdz9nXsAaGpu4o8vPKGy+rVu7xi1C+9vO4QX3mznoveeC8A1z97EHS/dx+n7fJyvv+/vWdnZwbee+D4AWw3eknMO/ByJxGvLFvLNGd+tsnxtYpHWNiFW0ObQKW6uLp/5rapLUD95YO6cqktQP/nRcd/ut3bu7PvP6dPv+wsOPb/y5RhepyhJKiJqsMTQUJQkFdHfc4qbghfvS5KU2SlKkoqow7+naChKkoqIGgw+GoqSpCLsFCVJylxoI0lSjdgpSpKK8DpFSZIy5xQlScqcU5QkqUbsFCVJRTTVoM8yFCVJRdRh+NRQlCQVYShKkpQ11eCSjMYfAJYkqRA7RUlSEQ6fSpKUefG+JEmZt3mTJClrisZfptL4n0CSpELsFCVJRbjQRpKkzDlFSZKyOqw+dU5RkqTMTlGSVITDp5IkZXUYPjUUJUlFRA2uUzQUJUlF1GH4tPFjXZKkQuwUJUlFOKcoSVLmHW0kScqaajCnaChKkoqoQ6foQhtJkjI7RUlSEV6nKElS5pyiJEmZc4qSJNWInaIkqYg63ObNUJQkFVGH4VNDUZJUhAttJEnK6nBJRuN/AknSZiEiroqIBRExc43tn4uIZyPiqYj4WrftZ0fEnLzvmN6cw05RklTEJlho8z3gm8APVp8zYgIwCdgnpfRWRLTk7XsCHwX2ArYHfhYRu6eUOtZ3AjtFSVIREdGnR09SSncBr62x+XTgwpTSW/mYBXn7JODalNJbKaXngDnAQT2dw1CUJBURffzfRtodeF9EPBgRd0bEgXn7WOClbse1523r5fCpJKmIvl6SERFTgCndNk1NKU3t4WUDgFHAIcCBwHURsTOsNWVTTzUYipKkt4UcgD2F4JragRtTSgl4KCI6gW3z9nHdjmsDXu7pzQxFbbSJO36g6hLUT87863+uugT1kx8d13/vXdF1ij8GjgSmR8TuwCDgFeAnwL9HxMV0LbTZDXiopzczFCVJRfT3HW0i4hrgCGDbiGgHvgxcBVyVL9NYDnwid41PRcR1wNPASuAzPa08BUNRklRI9PPazZTSievY9WfrOP6rwFc35ByuPpUkKbNTlCQV4Q3BJUnK/KejJEnKmuwUJUnqUodO0YU2kiRldoqSpCJcaCNJUtbf1yluCoaiJKkIO0VJkrKK7n1aVOP3upIkFWKnKEkqwuFTSZKyOlynaChKkoqoQ6fonKIkSZmdoiSpCK9TlCQp84bgkiRlLrSRJClzoY0kSTVipyhJKsLhU0mSsjoMnxqKkqQimmowI2coSpKKqEOn2PixLklSIXaKkqQiXGgjSVJWh+FTQ1GSVEQdOkXnFCVJyuwUJUlF1KFTNBQlSWU4pyhJUhc7RUmSsjqsPnWhjSRJmZ2iJKkIh08lScoMRUmSsjrMKRqKkqQi6tAputBGkqTMTlGSVEQdOkVDUZJUhHOKkiRldegUnVOUJCmzU5QkFeHwqSRJWR2GTw1FSVIRhqJWu/fue7nogn+is6OTEz4ymVNO+4uqS1If/OSan3L7TdOICHbcZRyf+/tP88yTs/nepT9k5YqV7LLHTnz23NNpHtBcdanqpaamJh657GbmvjKPP/z7P+eui29gxNDhALSM3IaHnpnBCV85lXeM24Xv/vXFvHvXvTn3u1/jG9dfUXHljWNTDJ9GxF8BpwIJeBL4JLAdcC2wNfAocHJKafnGvL8LbQro6Ojg/PMu5FtXfJP//D83cOvNt/KrOb+quixtpFcXvMZPf3QLX//ehVx6zTfo6Ozkrtvu4V/+4TK+eN4XuPSabzB6zGim3Xxn1aVqA3zhhFOY9eKc1c/ff+Yfs/+njmH/Tx3D/U8/yo333ALAa4sW8vnL/idfNwzfdiJiLPB54ICU0t5AM/BR4CLgkpTSbsDrwCkbew5DsYCZT85k3A7jaBvXxsBBA5l47DFMnza96rLUBx0dnSx/azkdKztYvmw5WwzZgoGDBjB2h+0B2Pegfbh/2oMVV6neGrvtdhx/8FF855Z//719w4cM48j93sOP77sNgN8ufJVHZj/OipUrN3WZDS/6+L9eGgAMiYgBwFDgN8CRwPV5//eByRv7GXoMxYjYIyKOiojha2yfuLEnrZsF8xcwZkzr6uctY1qZv+C3FVakvtimZWsmn/SHnDbpdD55/BSGDh/KYUcfSsfKDubM6hoBuH/aA7yy4JWKK1Vv/fPpX+Fv/u2rdHam39t3wmET+flj97JoyeIKKquX/g7FlNJc4OvAi3SF4RvAL4CFKaVVf8W0A2M39jOsNxQj4vPATcDngJkRManb7vM39qR1k37/56wG082br8VvLuahux7miv+8jKv+6wqWLV3GnbfezRfPO4MrL/k+X/rk2QwZNoTmZucTG8HxBx/FgoWv8Ogvn1zr/hMnTOaaO27axFXVU0T09TElIh7p9piyxvuPAiYBOwHbA8OAY9dSylp+K/dOTwttTgP+IKW0OCLGA9dHxPiU0r+wnt/7+YNMAfjm5f9a+0UnrWNamDdv/urnC+bNp6VldIUVqS8ef/hJWrZvYatRWwJw6ISDeebJ2Rxx7Pu5YOo/AvDYA48z98WXqyxTvXTYXgfyR4d+kOMOOpItBg1my6Ej+OFZl3LyRZ9n6xEjOWiP/TjhK6dWXaaAlNJUYOp6DjkaeC6l9FuAiLgReA8wMiIG5G6xDdjoH86ehk+bU0qLc7HPA0cAx0bExawnFFNKU1NKB6SUDqh7IALstfdevPjCi7S3z2XF8hXcesttHD7hiKrL0kYa3bots2f+kreWvUVKiScefpK28WNZ+NobAKxYvoIbf3gTEz/8wYorVW+cc9WFjPvYgex08qF89KufYdqMezn5os8D8CeHf4ifPvAz3lrxVsVV1kX08dGjF4FDImJodC11PQp4GrgD+Eg+5hN0jXBulJ46xXkRsV9KaQZA7hg/BFwFvGtjT1o3AwYM4Oxzz+L00z5NZ2cnk0+YxK677VJ1WdpIu++9G+858hDO/PhZNDc3s9Pu4zlm8tFc/e1reeTeR+ns7GTihz/IPgfsXXWp6qOPHjGJC6+97P/b1jpqNI9cdjNbDh1OZ+rkjA+fyp6nTnDOsRf6+5KMlNKDEXE9XZddrAQeo6uz/C/g2og4L2+7cmPPEWltE2Krdka0AStTSvPWsu+wlNK9PZ1gWceSjR7b1dvbc4t+WXUJ6id7/snxVZegfpJub++35Pr1omf79Pt+5xHvqHw5xno7xZRS+3r29RiIkqTNRx3uaON1ipIkZd7mTZJUhP9KhiRJWR2GTw1FSVIRhqIkSVkdhk9daCNJUmanKEkqwuFTSZKyOgyfGoqSpCLq0Ck6pyhJUmanKEkqpPE7RUNRklRE40eioShJKsSFNpIkrdb4oehCG0mSMjtFSVIRjd8nGoqSpGIaPxYNRUlSEXVYaOOcoiRJmaEoSVLm8KkkqYg63PvUUJQkFVGHUHT4VJKkzFCUJClz+FSSVISXZEiSVCN2ipKkIuqw0MZQlCQV0vih6PCpJEmZnaIkqYjG7xMNRUlSIXVYfWooSpIKMRQlSQLqEIkutJEkaTU7RUlSIY3fKxqKkqQi6rDQxuFTSZIyQ1GSpMzhU0lSEd77VJKk1QxFSZKAOkSioShJKsTVp5Ik1YidoiSpkMbvFA1FSVIRjR+JhqIkqZjGj0XnFCVJRUREnx69PMfEiHg2IuZExN+W/gyGoiSpIUREM3AZcCywJ3BiROxZ8hyGoiSpURwEzEkp/TqltBy4FphU8gTOKUqSitgEt3kbC7zU7Xk7cHDJE/R7KG7RPLTxZ143QERMSSlNrbqOTeGdI/etuoRNanP63qbb26suYZPanL63/amvv+8jYgowpdumqWt8X9b2/qkv51yTw6flTen5EDUov7f15ff2bSClNDWldEC3x5p/qLQD47o9bwNeLlmDoShJahQPA7tFxE4RMQj4KPCTkidwTlGS1BBSSisj4rPAbUAzcFVK6amS5zAUy3Neor783taX39sGkVK6Gbi5v94/Uio6RylJUsNyTlGSpMxQLKS/bz2k6kTEVRGxICJmVl2LyomIcRFxR0TMioinIuILVdek6jl8WkC+9dBs4AN0LRl+GDgxpfR0pYWpiIh4P7AY+EFKae+q61EZEbEdsF1K6dGIGAH8Apjsz+3mzU6xjH6/9ZCqk1K6C3it6jpUVkrpNymlR/PXi4BZdN0xRZsxQ7GMtd16yB8uqUFExHhgf+DBaitR1QzFMvr91kOS+kdEDAduAM5IKb1ZdT2qlqFYRr/fekhSeRExkK5AvDqldGPV9ah6hmIZ/X7rIUllRde/anslMCuldHHV9ejtwVAsIKW0Elh166FZwHWlbz2k6kTENcD9wDsioj0iTqm6JhVxGHAycGREzMiP46ouStXykgxJkjI7RUmSMkNRkqTMUJQkKTMUJUnKDEVJkjJDUZKkzFCUJCkzFCVJyv4vEjTIMPcA0lYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_arg=np.argmax(y_test_seq_HE, axis=1)\n",
    "Y_pred = np.argmax(model2.predict(X_test_seq_HE),axis=1)\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test_arg, Y_pred)\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))  # 그래프 크기 조절 (너비 8, 높이 6)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 438us/step - loss: 0.6586 - accuracy: 0.6453\n",
      "model saved at  C:/resources/2weeks/HE_Model.h5\n",
      "Accuracy >64.525408\n",
      "Base Loss >0.66\n"
     ]
    }
   ],
   "source": [
    "base_loss,base_accuracy=model2.evaluate(X_test_seq_HE, y_test_seq_HE)\n",
    "\n",
    "model_file2='C:/resources/2weeks/HE_Model.h5'\n",
    "  \n",
    "tf.keras.models.save_model(model2, model_file2, include_optimizer=False)\n",
    "print('model saved at ', model_file2)\n",
    "score=base_accuracy*100\n",
    "print('Accuracy >{:f}'.format(score))\n",
    "print('Base Loss >{:.2f}'.format(base_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-trained Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Base 모델을 로드 (RA_Model.h5)\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "base_model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 531us/step - loss: 0.6465 - accuracy: 0.6826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6465001106262207, 0.6826462149620056]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "base_model.evaluate(X_test_seq_LE, y_test_seq_LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 656us/step - loss: 1.1676 - accuracy: 0.5369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1675941944122314, 0.536912739276886]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test_seq_HE, y_test_seq_HE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  7\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 모델의 층을 동결 (학습되지 않도록 설정)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 1, 50)             16600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 21,949\n",
      "Trainable params: 2,703\n",
      "Non-trainable params: 19,246\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def remove_last_layers(model, num_layers_to_remove):\n",
    "    # 모델의 레이어를 하나씩 슬라이스해서 앞의 레이어만 가져옴\n",
    "    model_layers = model.layers[:-num_layers_to_remove]  # 마지막 레이어부터 지정된 갯수만큼 제외\n",
    "    new_model = models.Sequential(model_layers)  # 새로운 모델에 해당 레이어들만 추가\n",
    "    return new_model\n",
    "\n",
    "\n",
    "# 출력층부터 1개의 레이어를 삭제\n",
    "new_model = remove_last_layers(base_model, 1)\n",
    "\n",
    "# 새로운 출력층 추가\n",
    "new_model.add(layers.Dense(50, activation='relu'))\n",
    "new_model.add(layers.Dense(n_outputs, activation='softmax'))  # 예: 10개의 클래스\n",
    "new_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "# 모델 요약 출력\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv1D object at 0...</td>\n",
       "      <td>conv1d</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling1D object at 0...</td>\n",
       "      <td>max_pooling1d</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.recurrent_v2.LSTM object at 0x00...</td>\n",
       "      <td>lstm_25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.layers.core.Dropout object at 0x0000023...</td>\n",
       "      <td>dropout</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.layers.core.Flatten object at 0x0000023...</td>\n",
       "      <td>flatten_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x00000236A...</td>\n",
       "      <td>dense_51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x000002369...</td>\n",
       "      <td>dense_55</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x00000236A...</td>\n",
       "      <td>dense_56</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Layer Type     Layer Name  \\\n",
       "0  <keras.layers.convolutional.Conv1D object at 0...         conv1d   \n",
       "1  <keras.layers.pooling.MaxPooling1D object at 0...  max_pooling1d   \n",
       "2  <keras.layers.recurrent_v2.LSTM object at 0x00...        lstm_25   \n",
       "3  <keras.layers.core.Dropout object at 0x0000023...        dropout   \n",
       "4  <keras.layers.core.Flatten object at 0x0000023...      flatten_5   \n",
       "5  <keras.layers.core.Dense object at 0x00000236A...       dense_51   \n",
       "6  <keras.layers.core.Dense object at 0x000002369...       dense_55   \n",
       "7  <keras.layers.core.Dense object at 0x00000236A...       dense_56   \n",
       "\n",
       "   Layer Trainable  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  \n",
       "5            False  \n",
       "6             True  \n",
       "7             True  "
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in new_model.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 0.8590 - accuracy: 0.5055 - val_loss: 0.7648 - val_accuracy: 0.4441\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.7331 - accuracy: 0.4995 - val_loss: 0.7660 - val_accuracy: 0.4441\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 0s 750us/step - loss: 0.7283 - accuracy: 0.5172 - val_loss: 0.7648 - val_accuracy: 0.5399\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.7279 - accuracy: 0.5023 - val_loss: 0.7660 - val_accuracy: 0.5495\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 0s 727us/step - loss: 0.7262 - accuracy: 0.5264 - val_loss: 0.7730 - val_accuracy: 0.4441\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 0s 761us/step - loss: 0.7283 - accuracy: 0.5147 - val_loss: 0.7671 - val_accuracy: 0.4441\n",
      "Epoch 7/20\n",
      "89/89 [==============================] - 0s 773us/step - loss: 0.7272 - accuracy: 0.5314 - val_loss: 0.7690 - val_accuracy: 0.4441\n",
      "Epoch 8/20\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.7275 - accuracy: 0.5108 - val_loss: 0.7652 - val_accuracy: 0.6294\n",
      "Epoch 9/20\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.7295 - accuracy: 0.5222 - val_loss: 0.7607 - val_accuracy: 0.5399\n",
      "Epoch 10/20\n",
      "89/89 [==============================] - 0s 830us/step - loss: 0.7299 - accuracy: 0.5027 - val_loss: 0.7656 - val_accuracy: 0.5272\n",
      "Epoch 11/20\n",
      "89/89 [==============================] - 0s 784us/step - loss: 0.7276 - accuracy: 0.5144 - val_loss: 0.7641 - val_accuracy: 0.6613\n",
      "Epoch 12/20\n",
      "89/89 [==============================] - 0s 739us/step - loss: 0.7268 - accuracy: 0.5286 - val_loss: 0.7604 - val_accuracy: 0.5399\n",
      "Epoch 13/20\n",
      "89/89 [==============================] - 0s 727us/step - loss: 0.7270 - accuracy: 0.5339 - val_loss: 0.7612 - val_accuracy: 0.6901\n",
      "Epoch 14/20\n",
      "89/89 [==============================] - 0s 693us/step - loss: 0.7247 - accuracy: 0.5257 - val_loss: 0.7597 - val_accuracy: 0.5399\n",
      "Epoch 15/20\n",
      "89/89 [==============================] - 0s 739us/step - loss: 0.7265 - accuracy: 0.5257 - val_loss: 0.7688 - val_accuracy: 0.4441\n",
      "Epoch 16/20\n",
      "89/89 [==============================] - 0s 727us/step - loss: 0.7278 - accuracy: 0.5236 - val_loss: 0.7680 - val_accuracy: 0.4441\n",
      "Epoch 17/20\n",
      "89/89 [==============================] - 0s 739us/step - loss: 0.7285 - accuracy: 0.5321 - val_loss: 0.7673 - val_accuracy: 0.4441\n",
      "Epoch 18/20\n",
      "89/89 [==============================] - 0s 761us/step - loss: 0.7251 - accuracy: 0.5236 - val_loss: 0.7624 - val_accuracy: 0.6613\n",
      "Epoch 19/20\n",
      "89/89 [==============================] - 0s 773us/step - loss: 0.7224 - accuracy: 0.5272 - val_loss: 0.7637 - val_accuracy: 0.5591\n",
      "Epoch 20/20\n",
      "89/89 [==============================] - 0s 773us/step - loss: 0.7217 - accuracy: 0.5286 - val_loss: 0.7597 - val_accuracy: 0.5399\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 1, 50)             16600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 21,949\n",
      "Trainable params: 2,703\n",
      "Non-trainable params: 19,246\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history3 = new_model.fit(X_train_seq_HE, y_train_seq_HE, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 500us/step - loss: 0.7563 - accuracy: 0.4516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7563194632530212, 0.4515819847583771]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test_seq_HE, y_test_seq_HE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fine Tunning 미세 조정</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "new_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv1D object at 0...</td>\n",
       "      <td>conv1d</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling1D object at 0...</td>\n",
       "      <td>max_pooling1d</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.recurrent_v2.LSTM object at 0x00...</td>\n",
       "      <td>lstm_25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.layers.core.Dropout object at 0x0000023...</td>\n",
       "      <td>dropout</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.layers.core.Flatten object at 0x0000023...</td>\n",
       "      <td>flatten_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x00000236A...</td>\n",
       "      <td>dense_51</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x000002369...</td>\n",
       "      <td>dense_55</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x00000236A...</td>\n",
       "      <td>dense_56</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Layer Type     Layer Name  \\\n",
       "0  <keras.layers.convolutional.Conv1D object at 0...         conv1d   \n",
       "1  <keras.layers.pooling.MaxPooling1D object at 0...  max_pooling1d   \n",
       "2  <keras.layers.recurrent_v2.LSTM object at 0x00...        lstm_25   \n",
       "3  <keras.layers.core.Dropout object at 0x0000023...        dropout   \n",
       "4  <keras.layers.core.Flatten object at 0x0000023...      flatten_5   \n",
       "5  <keras.layers.core.Dense object at 0x00000236A...       dense_51   \n",
       "6  <keras.layers.core.Dense object at 0x000002369...       dense_55   \n",
       "7  <keras.layers.core.Dense object at 0x00000236A...       dense_56   \n",
       "\n",
       "   Layer Trainable  \n",
       "0             True  \n",
       "1             True  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  \n",
       "5             True  \n",
       "6             True  \n",
       "7             True  "
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in new_model.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.7221 - accuracy: 0.5314 - val_loss: 0.7611 - val_accuracy: 0.4728\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.6035 - val_loss: 0.6882 - val_accuracy: 0.6869\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6720 - val_loss: 0.6613 - val_accuracy: 0.6869\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6780 - val_loss: 0.6814 - val_accuracy: 0.6486\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6688 - val_loss: 0.7145 - val_accuracy: 0.6134\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.6699 - val_loss: 0.6911 - val_accuracy: 0.6422\n",
      "Epoch 7/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.6723 - val_loss: 0.6644 - val_accuracy: 0.6869\n",
      "Epoch 8/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6759 - val_loss: 0.6730 - val_accuracy: 0.6773\n",
      "Epoch 9/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6848 - val_loss: 0.6608 - val_accuracy: 0.6997\n",
      "Epoch 10/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6759 - val_loss: 0.6747 - val_accuracy: 0.6741\n",
      "Epoch 11/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6755 - val_loss: 0.6733 - val_accuracy: 0.6773\n",
      "Epoch 12/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6752 - val_loss: 0.6788 - val_accuracy: 0.6613\n",
      "Epoch 13/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6787 - val_loss: 0.6700 - val_accuracy: 0.6805\n",
      "Epoch 14/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6798 - val_loss: 0.6867 - val_accuracy: 0.6390\n",
      "Epoch 15/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6798 - val_loss: 0.6594 - val_accuracy: 0.6837\n",
      "Epoch 16/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.6755 - val_loss: 0.6611 - val_accuracy: 0.6805\n",
      "Epoch 17/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.6773 - val_loss: 0.6653 - val_accuracy: 0.6773\n",
      "Epoch 18/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6805 - val_loss: 0.6904 - val_accuracy: 0.6326\n",
      "Epoch 19/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6265 - accuracy: 0.6826 - val_loss: 0.6825 - val_accuracy: 0.6550\n",
      "Epoch 20/20\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6720 - val_loss: 0.6617 - val_accuracy: 0.6837\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 32)             96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 1, 50)             16600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 21,949\n",
      "Trainable params: 21,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history3 = new_model.fit(X_train_seq_HE, y_train_seq_HE, epochs = 20, batch_size = 32, validation_split = 0.1, shuffle = True)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 500us/step - loss: 0.6379 - accuracy: 0.6903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6379235982894897, 0.690316379070282]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test_seq_HE, y_test_seq_HE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
